{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6bb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, models, layers, utils, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1e762b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_675739/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 16:30:54.057039: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-02 16:30:59.019477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 14639 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:1b:00.0, compute capability: 7.0\n",
      "2022-03-02 16:30:59.021382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 14639 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:1c:00.0, compute capability: 7.0\n",
      "2022-03-02 16:30:59.023036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:2 with 14639 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3d:00.0, compute capability: 7.0\n",
      "2022-03-02 16:30:59.024553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:3 with 14639 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3e:00.0, compute capability: 7.0\n",
      "2022-03-02 16:30:59.026126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Created device /device:GPU:4 with 14639 MB memory:  -> device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:88:00.0, compute capability: 7.0\n",
      "2022-03-02 16:30:59.027617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:5 with 14639 MB memory:  -> device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2022-03-02 16:30:59.029101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:6 with 14639 MB memory:  -> device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:db:00.0, compute capability: 7.0\n",
      "2022-03-02 16:30:59.030540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:7 with 14639 MB memory:  -> device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:dd:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# check available GPUs\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a76bbd",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d860cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "img_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061cec5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (50000, 32, 32, 3)\n",
      "y_train: (50000, 1)\n",
      "x_val: (10000, 32, 32, 3)\n",
      "y_val: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val) = datasets.cifar10.load_data()\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_val:', x_val.shape)\n",
    "print('y_val:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b78d29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization 0~1\n",
    "x_train = x_train/255.\n",
    "x_val = x_val/255.\n",
    "\n",
    "# one hot encoding\n",
    "y_train = utils.to_categorical(y_train, num_classes= num_classes)\n",
    "y_val = utils.to_categorical(y_val, num_classes= num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16e9e1",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d528810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "inputs = layers.Input(shape=(img_size, img_size, 3))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "prediction = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1d37be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,294,090\n",
      "Trainable params: 4,293,642\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10e004",
   "metadata": {},
   "source": [
    "# Multi Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b2c9e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "# 抓所有認得到的GPU,並在這些GPU上設定同步策略\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy() \n",
    "\n",
    "# 指定特定GPU\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7378ecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 16:53:30.163130: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 8s 8ms/step - loss: 1.2021 - accuracy: 0.5863 - val_loss: 1.0580 - val_accuracy: 0.6386\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.7526 - accuracy: 0.7352 - val_loss: 0.8825 - val_accuracy: 0.6916\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.5156 - accuracy: 0.8202 - val_loss: 0.8973 - val_accuracy: 0.7129\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.3168 - accuracy: 0.8891 - val_loss: 1.0393 - val_accuracy: 0.7121\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.1965 - accuracy: 0.9327 - val_loss: 1.3773 - val_accuracy: 0.6557\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.1399 - accuracy: 0.9511 - val_loss: 1.2845 - val_accuracy: 0.7044\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.1247 - accuracy: 0.9569 - val_loss: 1.3464 - val_accuracy: 0.7000\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.1107 - accuracy: 0.9625 - val_loss: 1.2917 - val_accuracy: 0.7198\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0881 - accuracy: 0.9713 - val_loss: 2.2461 - val_accuracy: 0.6522\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0836 - accuracy: 0.9725 - val_loss: 1.7336 - val_accuracy: 0.6981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f61742e54c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 這裡採同步訓練,每個step算完會\"聚合\"一次梯度再更新; 異地不會聚合,每個GPU算完會依其結果直接更新\n",
    "with mirrored_strategy.scope():\n",
    "    model = model\n",
    "\n",
    "model.compile(loss=losses.categorical_crossentropy, \n",
    "              optimizer=optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8196032",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2328923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.7336 - accuracy: 0.6981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.733648657798767, 0.6980999708175659]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "404b771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 觀察每張GPU分布運算情形, 原先batch_size為64, 平均分到8張GPU後,每個step各自負責64/8=8筆資料\n",
    "mirrored_strategy.num_replicas_in_sync"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autokeras",
   "language": "python",
   "name": "autokeras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
